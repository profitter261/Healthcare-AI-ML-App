{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZnOLov4OBn5qp3tIWo9pY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/profitter261/Healthcare-AI-ML-App/blob/main/Medical_Translator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6eb49d1"
      },
      "source": [
        "# Task\n",
        "Compare the NLLB-200 and mBART-200 models for multilingual medical translation using the BLEU score and choose the best one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d0758a6"
      },
      "source": [
        "## Load and fix models\n",
        "\n",
        "### Subtask:\n",
        "Ensure that both the NLLB-200 and mBART models and their tokenizers are loaded correctly. This includes addressing the previous error with the NLLB tokenizer's `lang_code_to_id` attribute.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb47cb7b"
      },
      "source": [
        "**Reasoning**:\n",
        "Import the necessary classes from the `transformers` library and load the NLLB-200 model and tokenizer, addressing the potential issue with `lang_code_to_id`. Then, load the mBART-200 model and tokenizer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75d0832f",
        "outputId": "7351b53d-9d6f-4da4-fbba-27d879a92acc"
      },
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "\n",
        "# Load NLLB-200 model and tokenizer\n",
        "# Note: As of some versions, the NLLB tokenizer might have issues with lang_code_to_id.\n",
        "# We will try loading it directly first. If it fails, we would need a workaround,\n",
        "# but for now, we assume the current transformers version handles it or we will address it if an error occurs.\n",
        "nllb_model_name = \"facebook/nllb-200-distilled-600M\"\n",
        "nllb_tokenizer = AutoTokenizer.from_pretrained(nllb_model_name)\n",
        "nllb_model = AutoModelForSeq2SeqLM.from_pretrained(nllb_model_name)\n",
        "\n",
        "# Load mBART-200 model and tokenizer\n",
        "mbart_model_name = \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        "mbart_tokenizer = AutoTokenizer.from_pretrained(mbart_model_name)\n",
        "mbart_model = AutoModelForSeq2SeqLM.from_pretrained(mbart_model_name)\n",
        "\n",
        "print(\"Models and tokenizers loaded successfully.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models and tokenizers loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ccecca9"
      },
      "source": [
        "## Prepare medical translation data\n",
        "\n",
        "### Subtask:\n",
        "Obtain or create a dataset for medical translation with source text in one language and corresponding translations in multiple target languages.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cf108e4"
      },
      "source": [
        "**Reasoning**:\n",
        "Define a Python dictionary named `medical_data` to store the medical translation data as instructed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12ab6db6",
        "outputId": "38c14acb-b745-4f48-a7a6-45ea2a534643"
      },
      "source": [
        "# Updated medical data with Indian languages\n",
        "medical_data = {\n",
        "    'English': [\n",
        "        'Fever and cough are common symptoms of the flu.',\n",
        "        'Hypertension is a major risk factor for heart disease.',\n",
        "        'Diabetes requires careful management of blood sugar levels.',\n",
        "        'The patient presented with severe abdominal pain.',\n",
        "        'Regular exercise is beneficial for cardiovascular health.',\n",
        "        'Please take this medicine three times a day.', # Added more sentences\n",
        "        'The test results came back positive.',\n",
        "        'Consult a doctor if symptoms persist.',\n",
        "        'Maintain a healthy diet for better recovery.',\n",
        "        'Vaccination is important for preventing diseases.'\n",
        "    ],\n",
        "    'Hindi': [\n",
        "        'बुखार और खांसी फ्लू के सामान्य लक्षण हैं।',\n",
        "        'उच्च रक्तचाप हृदय रोग के लिए एक प्रमुख जोखिम कारक है।',\n",
        "        'मधुमेह में रक्त शर्करा के स्तर का सावधानीपूर्वक प्रबंधन आवश्यक है।',\n",
        "        'रोगी को पेट में तेज दर्द हुआ।',\n",
        "        'नियमित व्यायाम हृदय स्वास्थ्य के लिए फायदेमंद है।',\n",
        "        'कृपया यह दवा दिन में तीन बार लें।', # Added corresponding translations\n",
        "        'परीक्षण के परिणाम सकारात्मक आए।',\n",
        "        'यदि लक्षण बने रहें तो डॉक्टर से सलाह लें।',\n",
        "        'बेहतर रिकवरी के लिए स्वस्थ आहार बनाए रखें।',\n",
        "        'टीकाकरण बीमारियों को रोकने के लिए महत्वपूर्ण है।'\n",
        "    ],\n",
        "    'Bengali': [\n",
        "        'জ্বর এবং কাশি ফ্লুর সাধারণ লক্ষণ।',\n",
        "        'উচ্চ রক্তচাপ হৃদরোগের একটি প্রধান ঝুঁকির কারণ।',\n",
        "        'ডায়াবেটিসের জন্য রক্তে শর্করার মাত্রার সতর্ক ব্যবস্থাপনা প্রয়োজন।',\n",
        "        'রোগী তীব্র পেটে ব্যথা নিয়ে হাজির হয়েছেন।',\n",
        "        'নিয়মিত ব্যায়াম কার্ডিওভাসকুলার স্বাস্থ্যের জন্য উপকারী।',\n",
        "        'অনুগ্রহ করে দিনে তিনবার এই ঔষধ সেবন করুন।', # Added corresponding translations\n",
        "        'পরীক্ষার ফলাফল ইতিবাচক এসেছে।',\n",
        "        'যদি লক্ষণগুলি অব্যাহত থাকে তবে ডাক্তারের সাথে পরামর্শ করুন।',\n",
        "        'ভালো পুনরুদ্ধারের জন্য স্বাস্থ্যকর খাবার গ্রহণ করুন।',\n",
        "        'রোগ প্রতিরোধের জন্য টিকাদান গুরুত্বপূর্ণ।'\n",
        "    ],\n",
        "     'Tamil': [\n",
        "        'காய்ச்சல் மற்றும் இருமல் காய்ச்சலின் பொதுவான அறிகுறிகளாகும்.',\n",
        "        'உயர் இரத்த அழுத்தம் இதய நோய்க்கு ஒரு முக்கிய ஆபத்து காரணி.',\n",
        "        'நீரிழிவு நோய்க்கு இரத்த சர்க்கரை அளவுகளை கவனமாக நிர்வகிக்க வேண்டும்.',\n",
        "        'நோயாளிக்கு கடுமையான வயிற்று வலி ஏற்பட்டது.',\n",
        "        'வழக்கமான உடற்பயிற்சி இருதய ஆரோக்கியத்திற்கு நன்மை பயக்கும்.',\n",
        "        'இந்த மருந்தை ஒரு நாளைக்கு மூன்று முறை எடுத்துக் கொள்ளுங்கள்.', # Added corresponding translations\n",
        "        'சோதனை முடிவுகள் நேர்மறையாக வந்தன.',\n",
        "        'அறிகுறிகள் தொடர்ந்தால் மருத்துவரை அணுகவும்.',\n",
        "        'சிறந்த மீட்புக்கு ஆரோக்கியமான உணவை பராமரிக்கவும்.',\n",
        "        'நோய்களைத் தடுக்க தடுப்பூசி முக்கியம்.'\n",
        "    ]\n",
        "}\n",
        "\n",
        "print(\"Medical translation data dictionary updated with Indian languages.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Medical translation data dictionary updated with Indian languages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73ced449"
      },
      "source": [
        "## Translate text using models\n",
        "\n",
        "### Subtask:\n",
        "Use the loaded NLLB-200 and mBART models to translate the source text from the medical dataset to the target languages.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3162ae2"
      },
      "source": [
        "**Reasoning**:\n",
        "Define source and target languages, initialize translation dictionaries, and then iterate through the source sentences and target languages to generate translations using both NLLB and mBART models, storing the results in the respective dictionaries. Finally, print the translation dictionaries.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZOwtZS0Qrgg",
        "outputId": "f0a6761f-26cf-4951-cfb4-6e0bfcea0653"
      },
      "source": [
        "# Updated translation code to use Indian languages\n",
        "\n",
        "source_language = 'English'\n",
        "target_languages = ['Hindi', 'Bengali', 'Tamil'] # Updated target languages\n",
        "\n",
        "nllb_translations = {lang: [] for lang in target_languages}\n",
        "mbart_translations = {lang: [] for lang in target_languages}\n",
        "\n",
        "# Mapping language names to NLLB language codes\n",
        "# Need to find correct NLLB codes for Hindi, Bengali, Tamil\n",
        "nllb_lang_codes = {\n",
        "    'English': 'eng_Latn',\n",
        "    'Hindi': 'hin_Deva', # NLLB code for Hindi\n",
        "    'Bengali': 'ben_Beng', # NLLB code for Bengali\n",
        "    'Tamil': 'tam_Taml' # NLLB code for Tamil\n",
        "}\n",
        "\n",
        "# Mapping language names to mBART language codes\n",
        "# Need to find correct mBART codes for Hindi, Bengali, Tamil\n",
        "mbart_lang_codes = {\n",
        "    'English': 'en_XX',\n",
        "    'Hindi': 'hi_IN', # mBART code for Hindi\n",
        "    'Bengali': 'bn_IN', # mBART code for Bengali\n",
        "    'Tamil': 'ta_IN' # mBART code for Tamil\n",
        "}\n",
        "\n",
        "\n",
        "for sentence in medical_data[source_language]:\n",
        "    # NLLB Translation\n",
        "    nllb_tokenizer.src_lang = nllb_lang_codes[source_language]\n",
        "    encoded_nllb = nllb_tokenizer(sentence, return_tensors=\"pt\")\n",
        "\n",
        "    for target_lang in target_languages:\n",
        "        # Corrected: Use the language code directly for forced_bos_token_id for NLLB\n",
        "        generated_tokens_nllb = nllb_model.generate(**encoded_nllb, forced_bos_token_id=nllb_tokenizer.convert_tokens_to_ids(nllb_lang_codes[target_lang]))\n",
        "        nllb_translations[target_lang].append(nllb_tokenizer.batch_decode(generated_tokens_nllb, skip_special_tokens=True)[0])\n",
        "\n",
        "    # mBART Translation\n",
        "    encoded_mbart = mbart_tokenizer(sentence, return_tensors=\"pt\")\n",
        "\n",
        "    for target_lang in target_languages:\n",
        "        generated_tokens_mbart = mbart_model.generate(**encoded_mbart, forced_bos_token_id=mbart_tokenizer.lang_code_to_id[mbart_lang_codes[target_lang]])\n",
        "        mbart_translations[target_lang].append(mbart_tokenizer.batch_decode(generated_tokens_mbart, skip_special_tokens=True)[0])\n",
        "\n",
        "\n",
        "print(\"NLLB Translations:\")\n",
        "print(nllb_translations)\n",
        "print(\"\\nmBART Translations:\")\n",
        "print(mbart_translations)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLLB Translations:\n",
            "{'Hindi': ['बुखार और खांसी फ्लू के आम लक्षण हैं।', 'उच्च रक्तचाप हृदय रोग का एक प्रमुख जोखिम कारक है।', 'मधुमेह के लिए रक्त शर्करा के स्तर का सावधानीपूर्वक प्रबंधन करना आवश्यक है।', 'रोगी को गंभीर पेट दर्द हुआ।', 'नियमित व्यायाम हृदय-संवहनी स्वास्थ्य के लिए फायदेमंद है।', 'कृपया यह दवा दिन में तीन बार लें।', 'परीक्षण के परिणाम सकारात्मक रहे।', 'यदि लक्षण जारी हैं तो डॉक्टर से परामर्श करें।', 'बेहतर स्वास्थ्य के लिए स्वस्थ आहार बनाए रखें।', 'रोगों की रोकथाम के लिए टीकाकरण महत्वपूर्ण है।'], 'Bengali': ['জ্বর ও কাশি হল ফ্লুর সাধারণ লক্ষণ।', 'উচ্চ রক্তচাপ হার্টের রোগের জন্য একটি বড় ঝুঁকিপূর্ণ কারণ।', 'ডায়াবেটিস রক্তে শর্করার মাত্রা যত্ন সহকারে নিয়ন্ত্রণ করতে হবে।', 'রোগীর পেটে তীব্র ব্যথা ছিল।', 'নিয়মিত ব্যায়াম হৃদরোগের জন্য উপকারী।', 'দয়া করে এই ঔষধটি দিনে তিনবার নিন।', 'পরীক্ষার ফলাফল ইতিবাচক ছিল।', 'লক্ষণগুলো যদি স্থায়ী হয় তাহলে ডাক্তারের সঙ্গে পরামর্শ করুন।', 'সুস্থতা পেতে স্বাস্থ্যকর খাদ্য গ্রহণ করুন।', 'রোগ প্রতিরোধে টিকা দেওয়া গুরুত্বপূর্ণ।'], 'Tamil': ['காய்ச்சல் மற்றும் இருமல் ஆகியவை காய்ச்சலின் பொதுவான அறிகுறிகள்.', 'உயர் இரத்த அழுத்தம் என்பது இதய நோய்க்கான முக்கிய ஆபத்து காரணி ஆகும்.', 'நீரிழிவு நோய் இரத்த சர்க்கரை அளவை கவனமாக கட்டுப்படுத்த வேண்டும்.', 'நோயாளிக்கு கடுமையான வயிற்று வலி இருந்தது.', 'உடற்பயிற்சிகள்', 'தயவுசெய்து இந்த மருந்தை ஒரு நாளைக்கு மூன்று முறை எடுத்துக் கொள்ளுங்கள்.', 'சோதனை முடிவுகள் நேர்மறையானவை.', 'அறிகுறிகள் தொடர்ந்தால் மருத்துவரிடம் கலந்தாலோசிக்கவும்.', 'ஆரோக்கியமான உணவைப் பராமரிக்கவும்.', 'நோய்களைத் தடுப்பதற்கு தடுப்பூசி முக்கியமானது.']}\n",
            "\n",
            "mBART Translations:\n",
            "{'Hindi': ['बुखार और खांसी फ्लू के सामान्य लक्षण हैं।', 'उच्च रक्तचाप हृदय रोग के लिए एक प्रमुख जोखिम कारक है।', 'मधुमेह के लिए रक्त शर्करा की मात्रा को सावधानी से नियंत्रित करना आवश्यक है।', 'रोगी को गंभीर पेट दर्द हुआ।', 'नियमित व्यायाम हृदयरोग के लिए लाभदायक है।', 'कृपया इस दवा को दिन में तीन बार लें।', 'परीक्षण के परिणाम सकारात्मक लौटे।', 'यदि लक्षण जारी हैं तो डॉक्टर से परामर्श करें।', 'बेहतर स्वास्थ्य के लिए स्वस्थ आहार बनाए रखें।', 'रोगों को रोकने के लिए टीकाकरण महत्वपूर्ण है।'], 'Bengali': ['ব ্ যাপ আর ক ্ ষন ্ যfluenzaের সাধারন রাস ্ তাবস ্ থা ।', 'হৃদরোগের গুরুত ্ বপূর ্ ণ ঝুঁকিপূর ্ ণ বিষয় হচ ্ ছে ।', 'ডায়াবেটিসের জন ্ য ব ্ যাক ্ তিগতভাবে ব ্ যবহার করা হচ ্ ছে ব ্ যাক ্ তিমান ডায়াবেটিসের पातळीর নিয়ন ্ ত ্ রণ ।', 'ব ্ যক ্ তি severe abdominal pain presented.', 'স ্ বাভাবিক শারীরবৃত ্ তির ব ্ যবহার হৃদস ্ পন ্ দন স ্ বাস ্ থ ্ যের ক ্ ষেত ্ রে উপকারপূর ্ ণ ।', 'শুধুমাত ্ র প ্ রতিদিন তিনবার ব ্ যবহার করে দিক ।', 'পরীক ্ ষার ফলাফল স ্ বাভাবিক মনে হয়েছে ।', 'যদি সংখ ্ যা থাকে, তাহলে একজন ডাক ্ তারに相談 করুন ।', 'স ্ বাস ্ থ ্ যপূর ্ ণ পুনরুদ ্ ধারের জন ্ য একজন স ্ বাস ্ থ ্ যপূর ্ ণ খাবার বজায় রাখেন ।', 'ব ্ যাক ্ তিষেধ প ্ রক ্ ষা ব ্ যাখ ্ যা করা অসুস ্ থতা বন ্ ধের জন ্ য জরুরি ।'], 'Tamil': ['பசி, காய்ச்சல் ஆகியவை இந்த நோய்யின் பொதுவான அறிகுறிகள்.', 'உயர் இரத்த அழுத்தம் இதய நோய்க்கான முக்கிய ஆபத்து காரணியாகும்.', 'நீரிழிவு இரத்தத்தில் சர்க்கரை அளவை கவனமாகக் கட்டுப்படுத்த வேண்டும்.', 'நோயாளிக்கு கடுமையான வயிறு வலி ஏற்பட்டது.', 'வழக்கமான உடற்பயிற்சி இருதய சுகாதாரத்திற்கு பயனுள்ளதாக இருக்கும்.', 'இந்த மருந்து நாளைக்கு மூன்று முறை புசியுங்கள்.', 'தேர்வு முடிவுகள் சாதகமாகத் திரும்பியது.', 'அறிகுறிகள் நீடித்திருந்தால் ஒரு மருத்துவரை ஆலோசியுங்கள்.', 'நல்ல உடல்நலத்திற்கான ஆரோக்கியமான உணவை பராமரிப்பீராக.', 'நோய்களை தடுப்பதில் தடுப்பு மருந்து மிகவும் முக்கியமானது.']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76599874"
      },
      "source": [
        "## Calculate bleu scores\n",
        "\n",
        "### Subtask:\n",
        "For each target language, calculate the BLEU score for the translations generated by both NLLB-200 and mBART against the reference translations in the dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4b07c47"
      },
      "source": [
        "**Reasoning**:\n",
        "Calculate the BLEU scores for NLLB and mBART translations against the reference translations for each target language.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dcaf6ad",
        "outputId": "e400794c-afe1-4920-bb81-fe8e6f9a3798"
      },
      "source": [
        "# Updated BLEU score calculation to use target_languages variable and smoothing\n",
        "\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "\n",
        "nllb_bleu_scores = {}\n",
        "mbart_bleu_scores = {}\n",
        "\n",
        "# target_languages variable is defined in the previous cell and used here\n",
        "# target_languages = ['Spanish', 'French'] # Ensure target_languages is defined\n",
        "\n",
        "# Define a smoothing function\n",
        "chencherry = SmoothingFunction()\n",
        "\n",
        "for lang in target_languages:\n",
        "    nllb_scores = []\n",
        "    mbart_scores = []\n",
        "    reference_translations = medical_data[lang]\n",
        "    nllb_generated_translations = nllb_translations[lang]\n",
        "    mbart_generated_translations = mbart_translations[lang]\n",
        "\n",
        "    for i in range(len(reference_translations)):\n",
        "        reference = [reference_translations[i].split()] # Reference must be a list of tokenized references\n",
        "        candidate_nllb = nllb_generated_translations[i].split() # Candidate must be tokenized\n",
        "        candidate_mbart = mbart_generated_translations[i].split() # Candidate must be tokenized\n",
        "\n",
        "        # Calculate BLEU score with smoothing\n",
        "        nllb_scores.append(sentence_bleu(reference, candidate_nllb, smoothing_function=chencherry.method1))\n",
        "        mbart_scores.append(sentence_bleu(reference, candidate_mbart, smoothing_function=chencherry.method1))\n",
        "\n",
        "    nllb_bleu_scores[lang] = nllb_scores\n",
        "    mbart_bleu_scores[lang] = mbart_scores\n",
        "\n",
        "print(\"NLLB BLEU Scores per sentence (with smoothing):\")\n",
        "print(nllb_bleu_scores)\n",
        "print(\"\\nmBART BLEU Scores per sentence (with smoothing):\")\n",
        "print(mbart_bleu_scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLLB BLEU Scores per sentence (with smoothing):\n",
            "{'Hindi': [0.5946035575013605, 0.5954165059120786, 0.5344445934790545, 0.10928032077900922, 0.5946035575013605, 1.0, 0.668740304976422, 0.14923729480049117, 0.7071067811865475, 0.08783602619713961], 'Bengali': [0.18575057999133598, 0.06030725360407769, 0.050712153369465586, 0.04739878501170794, 0.1315583108973614, 0.07201170728284921, 0.3976353643835253, 0.06030725360407769, 0.0808764862779457, 0.06389431042462725], 'Tamil': [0.20556680845025987, 0.13747081017605653, 0.07386099955930606, 0.668740304976422, 0, 0.8633400213704505, 0.17216896116316355, 0.16990442448471224, 0.069372929071742, 0.09554427922043669]}\n",
            "\n",
            "mBART BLEU Scores per sentence (with smoothing):\n",
            "{'Hindi': [1.0, 1.0, 0.047275266063115634, 0.10928032077900922, 0.09054992806599667, 0.4854917717073234, 0.668740304976422, 0.14923729480049117, 0.7071067811865475, 0.42728700639623407], 'Bengali': [0, 0.01428363257865929, 0.006471824245088331, 0, 0, 0.018476860420522198, 0.021105340631872645, 0.017033186037639283, 0.006471824245088331, 0], 'Tamil': [0.039281465090051315, 0.3628241434631103, 0.037684991644924185, 0.16068568378893033, 0.20205155046766235, 0.15557221826646012, 0.08034284189446518, 0.06389431042462725, 0.11362193664674995, 0]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a45545d3"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous command failed because `bleu_score` is not directly importable from `nltk.translate.bleu_score`. The correct function is `sentence_bleu`. I will fix the import and recalculate the scores.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5511e1fb"
      },
      "source": [
        "## Compare metrics\n",
        "\n",
        "### Subtask:\n",
        "Compare the calculated BLEU scores for both models across the different target languages.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9af6768f"
      },
      "source": [
        "**Reasoning**:\n",
        "Calculate the average BLEU score for each model and language, then print the results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85129292",
        "outputId": "85efc0c9-0da6-405a-8b20-5e8c978109ff"
      },
      "source": [
        "# Updated average BLEU score calculation to use target_languages variable\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "nllb_avg_bleu = {lang: np.mean(scores) for lang, scores in nllb_bleu_scores.items()}\n",
        "mbart_avg_bleu = {lang: np.mean(scores) for lang, scores in mbart_bleu_scores.items()}\n",
        "\n",
        "print(\"Average NLLB BLEU Scores:\")\n",
        "for lang, score in nllb_avg_bleu.items():\n",
        "    print(f\"{lang}: {score:.4f}\")\n",
        "\n",
        "print(\"\\nAverage mBART BLEU Scores:\")\n",
        "for lang, score in mbart_avg_bleu.items():\n",
        "    print(f\"{lang}: {score:.4f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average NLLB BLEU Scores:\n",
            "Hindi: 0.5041\n",
            "Bengali: 0.1150\n",
            "Tamil: 0.2456\n",
            "\n",
            "Average mBART BLEU Scores:\n",
            "Hindi: 0.4685\n",
            "Bengali: 0.0084\n",
            "Tamil: 0.1216\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a327ecd0"
      },
      "source": [
        "## Choose the best model\n",
        "\n",
        "### Subtask:\n",
        "Based on the BLEU score comparison, determine which model performs better for multilingual medical translation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fb5979e"
      },
      "source": [
        "**Reasoning**:\n",
        "Compare the average BLEU scores for NLLB and mBART for each language and determine the overall better performing model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46b45401",
        "outputId": "f808466a-001b-4f94-96f1-880616d67869"
      },
      "source": [
        "# Updated comparison code to use the dynamically determined target_languages\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "print(\"--- BLEU Score Comparison ---\")\n",
        "print(\"Language | NLLB Average BLEU | mBART Average BLEU | Better Model\")\n",
        "print(\"---------|-------------------|--------------------|--------------\")\n",
        "\n",
        "best_model_name = None\n",
        "nllb_total_avg = np.mean(list(nllb_avg_bleu.values()))\n",
        "mbart_total_avg = np.mean(list(mbart_avg_bleu.values()))\n",
        "\n",
        "# Use the keys from nllb_avg_bleu (which are the target languages)\n",
        "for lang in nllb_avg_bleu.keys():\n",
        "    nllb_score = nllb_avg_bleu[lang]\n",
        "    mbart_score = mbart_avg_bleu[lang]\n",
        "    better_lang_model = \"NLLB\" if nllb_score > mbart_score else \"mBART\"\n",
        "    print(f\"{lang:<8} | {nllb_score:<17.4f} | {mbart_score:<18.4f} | {better_lang_model}\")\n",
        "\n",
        "print(\"---------|-------------------|--------------------|--------------\")\n",
        "print(f\"Overall  | {nllb_total_avg:<17.4f} | {mbart_total_avg:<18.4f} | {'NLLB' if nllb_total_avg > mbart_total_avg else 'mBART'}\")\n",
        "\n",
        "if nllb_total_avg > mbart_total_avg:\n",
        "    best_model_name = \"NLLB-200\"\n",
        "else:\n",
        "    best_model_name = \"mBART-200\"\n",
        "\n",
        "print(f\"\\nBased on the average BLEU scores across languages, the better performing model is: {best_model_name}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- BLEU Score Comparison ---\n",
            "Language | NLLB Average BLEU | mBART Average BLEU | Better Model\n",
            "---------|-------------------|--------------------|--------------\n",
            "Hindi    | 0.5041            | 0.4685             | NLLB\n",
            "Bengali  | 0.1150            | 0.0084             | NLLB\n",
            "Tamil    | 0.2456            | 0.1216             | NLLB\n",
            "---------|-------------------|--------------------|--------------\n",
            "Overall  | 0.2883            | 0.1995             | NLLB\n",
            "\n",
            "Based on the average BLEU scores across languages, the better performing model is: NLLB-200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc3e17a2"
      },
      "source": [
        "## Present results\n",
        "\n",
        "### Subtask:\n",
        "Summarize the findings and present the BLEU scores and the conclusion about which model is better for the specified task.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93dd19bc"
      },
      "source": [
        "**Reasoning**:\n",
        "Summarize the findings by printing the average BLEU scores and the conclusion about the better model, as well as mentioning limitations.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "140a5487",
        "outputId": "768e3bef-69f1-41cb-c0b8-32e61fabaa8a"
      },
      "source": [
        "# Updated presentation of results to use the dynamically determined target_languages\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "print(\"--- Multilingual Medical Translation Model Comparison Summary (Indian Languages) ---\")\n",
        "print(\"\\nAverage BLEU Scores per Language:\")\n",
        "# Use the keys from nllb_avg_bleu (which are the target languages)\n",
        "for lang in nllb_avg_bleu.keys():\n",
        "    print(f\"{lang}:\")\n",
        "    print(f\"  NLLB-200: {nllb_avg_bleu[lang]:.4f}\")\n",
        "    print(f\"  mBART-200: {mbart_avg_bleu[lang]:.4f}\")\n",
        "\n",
        "nllb_total_avg = np.mean(list(nllb_avg_bleu.values()))\n",
        "mbart_total_avg = np.mean(list(mbart_avg_bleu.values()))\n",
        "\n",
        "print(f\"\\nOverall Average BLEU Score Across Languages:\")\n",
        "print(f\"  NLLB-200: {nllb_total_avg:.4f}\")\n",
        "print(f\"  mBART-200: {mbart_total_avg:.4f}\")\n",
        "\n",
        "# Determine the best model based on overall average BLEU\n",
        "best_model_name = \"NLLB-200\" if nllb_total_avg > mbart_total_avg else \"mBART-200\"\n",
        "\n",
        "print(f\"\\nConclusion:\")\n",
        "print(f\"Based on the average BLEU scores across Indian medical translations, the {best_model_name} model performed better.\")\n",
        "\n",
        "print(\"\\nLimitations of this comparison:\")\n",
        "print(f\"- The dataset size is small ({len(medical_data['English'])} sentences per language pair).\")\n",
        "print(f\"- Only a few Indian target languages ({', '.join(target_languages)}) were evaluated.\")\n",
        "print(\"- BLEU is an n-gram based metric and may not fully capture the nuances of translation quality, especially in specialized domains like medical text.\")\n",
        "print(\"- The quality of the provided reference translations in Indian languages is assumed to be high.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Multilingual Medical Translation Model Comparison Summary (Indian Languages) ---\n",
            "\n",
            "Average BLEU Scores per Language:\n",
            "Hindi:\n",
            "  NLLB-200: 0.5041\n",
            "  mBART-200: 0.4685\n",
            "Bengali:\n",
            "  NLLB-200: 0.1150\n",
            "  mBART-200: 0.0084\n",
            "Tamil:\n",
            "  NLLB-200: 0.2456\n",
            "  mBART-200: 0.1216\n",
            "\n",
            "Overall Average BLEU Score Across Languages:\n",
            "  NLLB-200: 0.2883\n",
            "  mBART-200: 0.1995\n",
            "\n",
            "Conclusion:\n",
            "Based on the average BLEU scores across Indian medical translations, the NLLB-200 model performed better.\n",
            "\n",
            "Limitations of this comparison:\n",
            "- The dataset size is small (10 sentences per language pair).\n",
            "- Only a few Indian target languages (Hindi, Bengali, Tamil) were evaluated.\n",
            "- BLEU is an n-gram based metric and may not fully capture the nuances of translation quality, especially in specialized domains like medical text.\n",
            "- The quality of the provided reference translations in Indian languages is assumed to be high.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b1b2140"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "Based on the BLEU score comparison, the NLLB-200 model performed better for multilingual medical translation across the tested languages (Spanish and French).\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   Both NLLB-200 and mBART-200 models and their tokenizers were successfully loaded.\n",
        "*   A small medical translation dataset was created with English source sentences and Spanish and French translations.\n",
        "*   Translations were generated for the English source sentences into Spanish and French using both the NLLB-200 and mBART-200 models.\n",
        "*   BLEU scores were calculated for each translated sentence against the reference translations.\n",
        "*   The average BLEU scores were computed for each language and model. For Spanish, NLLB achieved an average BLEU of 0.7565 compared to mBART's 0.6776. For French, NLLB scored 0.5939 while mBART scored 0.5747.\n",
        "*   The overall average BLEU score across both languages for NLLB was 0.6752, which was higher than mBART's overall average of 0.6261.\n",
        "*   Based on the overall average BLEU score, NLLB-200 was identified as the better-performing model in this comparison.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   Evaluate the models on a larger and more diverse medical translation dataset to confirm the findings and assess performance on a wider range of medical terminology and sentence structures.\n",
        "*   Incorporate human evaluation of translation quality, as BLEU scores are an automated metric and may not fully capture the nuances required for accurate medical translation.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02e65e42",
        "outputId": "5d24d51f-a543-4017-d90d-64024199e883"
      },
      "source": [
        "import os\n",
        "\n",
        "# Define the directory where you want to save the model and tokenizer\n",
        "save_directory = \"./nllb_medical_translator\"\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "if not os.path.exists(save_directory):\n",
        "    os.makedirs(save_directory)\n",
        "\n",
        "# Save the model and tokenizer\n",
        "nllb_model.save_pretrained(save_directory)\n",
        "nllb_tokenizer.save_pretrained(save_directory)\n",
        "\n",
        "print(f\"NLLB-200 model and tokenizer saved to: {save_directory}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py:3922: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 200}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLLB-200 model and tokenizer saved to: ./nllb_medical_translator\n"
          ]
        }
      ]
    }
  ]
}
